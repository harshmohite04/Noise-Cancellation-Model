{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_wav_files_from_directory(directory_path):\n",
    "    audio_files = []\n",
    "    sr = None  # Initialize sr with a default value\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            audio, sr = librosa.load(filepath, sr=None)\n",
    "            audio_files.append(audio)\n",
    "    if sr is None:  # Handle the case where no .wav files are found\n",
    "        raise ValueError(f\"No .wav files found in directory {directory_path}\")\n",
    "    return audio_files, sr\n",
    "\n",
    "noisy_train_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\data\\noisy_train\"\n",
    "clean_train_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\data\\clean_train\"\n",
    "noisy_test_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\data\\noisy_test\"\n",
    "clean_test_dir = r'C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\data\\clean_test'\n",
    "\n",
    "noisy_train_files, sr = load_wav_files_from_directory(noisy_train_dir)\n",
    "clean_train_files, sr = load_wav_files_from_directory(clean_train_dir)\n",
    "noisy_test_files, sr = load_wav_files_from_directory(noisy_test_dir)\n",
    "clean_test_files, sr = load_wav_files_from_directory(clean_test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_stft_length(audio_files, sr):\n",
    "    max_length = 0\n",
    "    for audio in audio_files:\n",
    "        stft_audio = librosa.stft(audio)\n",
    "        if stft_audio.shape[1] > max_length:\n",
    "            max_length = stft_audio.shape[1]\n",
    "    return max_length\n",
    "\n",
    "max_length = max(get_max_stft_length(noisy_train_files, sr),\n",
    "                 get_max_stft_length(clean_train_files, sr),\n",
    "                 get_max_stft_length(noisy_test_files, sr),\n",
    "                 get_max_stft_length(clean_test_files, sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_files(audio_files, sr, max_length):\n",
    "    magnitudes = []\n",
    "    phases = []\n",
    "    for audio in audio_files:\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        stft_audio = librosa.stft(audio)\n",
    "        magnitude, phase = librosa.magphase(stft_audio)\n",
    "        \n",
    "        # Pad the magnitude and phase to the max_length\n",
    "        magnitude_padded = np.pad(magnitude, ((0, 0), (0, max_length - magnitude.shape[1])), mode='constant')\n",
    "        phase_padded = np.pad(phase, ((0, 0), (0, max_length - phase.shape[1])), mode='constant')\n",
    "        \n",
    "        magnitudes.append(magnitude_padded)\n",
    "        phases.append(phase_padded)\n",
    "        \n",
    "    return np.array(magnitudes), np.array(phases)\n",
    "\n",
    "noisy_train_mag, noisy_train_phase = preprocess_audio_files(noisy_train_files, sr, max_length)\n",
    "clean_train_mag, clean_train_phase = preprocess_audio_files(clean_train_files, sr, max_length)\n",
    "noisy_test_mag, noisy_test_phase = preprocess_audio_files(noisy_test_files, sr, max_length)\n",
    "clean_test_mag, clean_test_phase = preprocess_audio_files(clean_test_files, sr, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"noisy_train_mag shape:\", noisy_train_mag.shape)\n",
    "print(\"clean_train_mag shape:\", clean_train_mag.shape)\n",
    "print(\"noisy_test_mag shape:\", noisy_test_mag.shape)\n",
    "print(\"clean_test_mag shape:\", clean_test_mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = noisy_train_mag[:, :, np.newaxis]\n",
    "y_train = clean_train_mag[:, :, np.newaxis]\n",
    "X_test = noisy_test_mag[:, :, np.newaxis]\n",
    "y_test = clean_test_mag[:, :, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    outputs = Conv2D(1, (3, 3), padding='same')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (noisy_train_mag.shape[1], noisy_train_mag.shape[2], 1)\n",
    "model = build_cnn_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_audio(magnitude, phase, sr, output_filepath):\n",
    "    stft_audio = magnitude * phase\n",
    "    cleaned_audio = librosa.istft(stft_audio)\n",
    "    librosa.output.write_wav(output_filepath, cleaned_audio, sr)\n",
    "\n",
    "# Predict and save the cleaned audio for the test set\n",
    "clean_test_pred = model.predict(X_test)\n",
    "clean_test_pred = clean_test_pred[..., 0]\n",
    "\n",
    "for i in range(len(clean_test_pred)):\n",
    "    output_filepath = f\"cleaned_test_audio_{i}.wav\"\n",
    "    save_cleaned_audio(clean_test_pred[i], noisy_test_phase[i], sr, output_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation\n",
    "\n",
    "def load_wav_files_from_directory(directory_path):\n",
    "    audio_files = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            audio, sr = librosa.load(filepath, sr=None)\n",
    "            audio_files.append(audio)\n",
    "    return audio_files, sr\n",
    "\n",
    "def preprocess_audio_files(audio_files, sr, max_length):\n",
    "    magnitudes = []\n",
    "    phases = []\n",
    "    for audio in audio_files:\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        stft_audio = librosa.stft(audio)\n",
    "        magnitude, phase = librosa.magphase(stft_audio)\n",
    "        \n",
    "        # Pad the magnitude and phase to the max_length\n",
    "        magnitude_padded = np.pad(magnitude, ((0, 0), (0, max_length - magnitude.shape[1])), mode='constant')\n",
    "        phase_padded = np.pad(phase, ((0, 0), (0, max_length - phase.shape[1])), mode='constant')\n",
    "        \n",
    "        magnitudes.append(magnitude_padded)\n",
    "        phases.append(phase_padded)\n",
    "        \n",
    "    return np.array(magnitudes), np.array(phases)\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    outputs = Conv2D(1, (3, 3), padding='same')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "noisy_train_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\Dataset\\noisy_trainset_wav\"\n",
    "clean_train_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\Dataset\\clean_trainset_wav\"\n",
    "noisy_test_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\Dataset\\noisy_testset_wav\"\n",
    "clean_test_dir = r\"C:\\Users\\Asus\\OneDrive\\Documents\\python\\Noise cancellation\\Dataset\\clean_testset_wav\"\n",
    "\n",
    "noisy_train_files, sr = load_wav_files_from_directory(noisy_train_dir)\n",
    "clean_train_files, sr = load_wav_files_from_directory(clean_train_dir)\n",
    "noisy_test_files, sr = load_wav_files_from_directory(noisy_test_dir)\n",
    "clean_test_files, sr = load_wav_files_from_directory(clean_test_dir)\n",
    "\n",
    "max_length = 674  # Set this to the maximum length of the STFT\n",
    "\n",
    "noisy_train_mag, noisy_train_phase = preprocess_audio_files(noisy_train_files, sr, max_length)\n",
    "clean_train_mag, clean_train_phase = preprocess_audio_files(clean_train_files, sr, max_length)\n",
    "noisy_test_mag, noisy_test_phase = preprocess_audio_files(noisy_test_files, sr, max_length)\n",
    "clean_test_mag, clean_test_phase = preprocess_audio_files(clean_test_files, sr, max_length)\n",
    "\n",
    "# Reshape the data correctly\n",
    "X_train = noisy_train_mag[..., np.newaxis]\n",
    "y_train = clean_train_mag[..., np.newaxis]\n",
    "X_test = noisy_test_mag[..., np.newaxis]\n",
    "y_test = clean_test_mag[..., np.newaxis]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Check the input shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "model = build_cnn_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
